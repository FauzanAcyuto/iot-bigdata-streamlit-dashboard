{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd2ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import boto3\n",
    "\n",
    "# import plotly.express as px\n",
    "# import polars as pl\n",
    "# import s3fs\n",
    "from contextlib import contextmanager\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5152549",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def init_duckdb_connection(aws_credentials: dict, ram_limit: str):\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    existing_keys = list(aws_credentials.keys())\n",
    "    required_keys = [\"aws_secret_access_key\", \"aws_access_key_id\", \"aws_region\"]\n",
    "    if not set(required_keys) <= set(existing_keys):\n",
    "        logger.exception(\n",
    "            f\"AWS Credentials doesn't contain required keys {required_keys}\"\n",
    "        )\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        logger.info(\"Initializing duckdb connection to S3\")\n",
    "        conn = duckdb.connect()\n",
    "        conn.execute(\"INSTALL httpfs;\")\n",
    "        conn.execute(\"LOAD httpfs;\")\n",
    "        conn.execute(f\"SET memory_limit = '{ram_limit}'\")\n",
    "        conn.execute(f\"SET s3_region = '{aws_credentials['aws_region']}';\")\n",
    "        conn.execute(\n",
    "            f\"SET s3_access_key_id = '{aws_credentials['aws_access_key_id']}';\"\n",
    "        )\n",
    "        conn.execute(\n",
    "            f\"SET s3_secret_access_key = '{aws_credentials['aws_secret_access_key']}';\"\n",
    "        )\n",
    "\n",
    "        yield conn\n",
    "    finally:\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(\"creds/creds.json\"), \"r\") as target:\n",
    "    creds = json.load(target)\n",
    "    storage_options = creds[\"AWS\"]\n",
    "storage_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028440f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with init_duckdb_connection(storage_options, \"4GB\") as conn:\n",
    "    conn.sql(\"\"\"\n",
    "    SELECT hiveperiod,COUNT(1) as jml\n",
    "    FROM read_parquet('s3://smartdbucket/datalog/cis_smartd_tbl_iot_scania/**/*.parquet')\n",
    "    GROUP BY hiveperiod\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7425d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with init_duckdb_connection(storage_options, \"4GB\") as conn:\n",
    "    conn.sql(\"\"\"\n",
    "    SELECT COUNT(1) as jml\n",
    "    FROM read_parquet('s3://smartdbucket/datalog/cis_smartd_tbl_iot_scania/**/*.parquet',hive_partitioning=true)\n",
    "    WHERE hiveperiod BETWEEN '2025-12-01' AND '2025-12-31' AND dstrct_code = 'BRCB'\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with init_duckdb_connection(storage_options, \"4GB\") as conn:\n",
    "    conn.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM read_json_auto('s3://smartdbucket/datalog/BRCB/SLS30I172/2025120705/2025120705.txt.gz')\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9daf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(list(storage_options.keys()))\n",
    "b = set([\"aws_secret_access_keya\", \"aws_access_key_id\", \"aws_region\"])\n",
    "\n",
    "b <= a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull gzip data from s3\n",
    "s3 = s3fs.S3FileSystem(\n",
    "    key=storage_options[\"aws_access_key_id\"],\n",
    "    secret=storage_options[\"aws_secret_access_key\"],\n",
    ")\n",
    "\n",
    "\n",
    "filepath = f\"s3://{storage_options['aws_bucket']}/datalog/{distrik}/{deviceid}/{hivehour}/{hivehour}\"\n",
    "bucketpath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc3c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3paths = s3.glob(filepath)\n",
    "s3paths = [i.replace(\"smartdbucket/datalog/BRCG/SLS30I009/\", \"\") for i in s3paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a37b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duckdb s3 connection config\n",
    "conn = duckdb.connect()\n",
    "\n",
    "conn.execute(\"INSTALL httpfs;\")\n",
    "conn.execute(\"LOAD httpfs;\")\n",
    "\n",
    "conn.execute(f\"SET s3_region = '{storage_options['aws_region']}';\")\n",
    "conn.execute(f\"SET s3_access_key_id = '{storage_options['aws_access_key_id']}';\")\n",
    "conn.execute(\n",
    "    f\"SET s3_secret_access_key = '{storage_options['aws_secret_access_key']}';\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e21738",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_unit = [\n",
    "    (\"SLS30I009\", \"LD780\"),\n",
    "    (\"SLS30I015\", \"LD781\"),\n",
    "    (\"SLS30I016\", \"LD782\"),\n",
    "    (\"SLS30I039\", \"LD776\"),\n",
    "    (\"SLS30I146\", \"LD772\"),\n",
    "    (\"SLS30I477\", \"LD778\"),\n",
    "    (\"SDLIR038\", \"LD921\"),\n",
    "    (\"SLS30I623\", \"LD783\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7791db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = conn.sql(f\"\"\"\n",
    "SELECT CAST(to_timestamp(heartbeat) as DATE)as tgl_utc,COUNT(1) as jml\n",
    "FROM read_json_auto('{bucketpath}')\n",
    "GROUP BY CAST(to_timestamp(heartbeat) as DATE)\n",
    "ORDER BY CAST(to_timestamp(heartbeat) as DATE)\n",
    "           \"\"\").pl()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3832b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a0884",
   "metadata": {},
   "outputs": [],
   "source": [
    "distrik = \"BRCG\"\n",
    "deviceid = \"SLS30I009\"\n",
    "\n",
    "\n",
    "def count_canbus_rows(conn, devid, hivehour):\n",
    "    bucketpath = f\"s3://{storage_options['aws_bucket']}/datalog/{distrik}/{devid}/{hivehour}/{hivehour}.txt.gz\"\n",
    "    df = conn.sql(f\"\"\"\n",
    "SELECT CAST(to_timestamp(heartbeat) as DATE)+ INTERVAL 8 HOUR as datetime_wita,heartbeat,unitno,deviceid,gpsspeed,gpsnumsat,vehiclespeed,speedsource,\n",
    "FROM read_json_auto('{bucketpath}')\n",
    "WHERE gpsspeed > 0 AND VehicleSpeed > 0\n",
    "           \"\"\").pl()\n",
    "    print(devid, \"unit has :\", len(df), \"rows\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58221198",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_unit[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8df9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "del main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hivehour = \"2025121*\"\n",
    "with duckdb.connect() as conn:\n",
    "    conn = duckdb.connect()\n",
    "\n",
    "    conn.execute(\"INSTALL httpfs;\")\n",
    "    conn.execute(\"LOAD httpfs;\")\n",
    "\n",
    "    conn.execute(f\"SET s3_region = '{storage_options['aws_region']}';\")\n",
    "    conn.execute(f\"SET s3_access_key_id = '{storage_options['aws_access_key_id']}';\")\n",
    "    conn.execute(\n",
    "        f\"SET s3_secret_access_key = '{storage_options['aws_secret_access_key']}';\"\n",
    "    )\n",
    "\n",
    "    for sls, unitno in list_unit:\n",
    "        try:\n",
    "            if main_df is not None:\n",
    "                df = count_canbus_rows(conn, sls, hivehour)\n",
    "                main_df = pl.concat([main_df, df])\n",
    "        except NameError:\n",
    "            # Code to execute if 'df' variable has not been assigned\n",
    "            main_df = count_canbus_rows(conn, sls, hivehour)\n",
    "            print(\"DataFrame variable is not defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "663f86db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = [\n",
    "    \"datalog/BRCG/SLS30I614/2025121212/2025121212.txt.gz\",\n",
    "    \"datalog/BRCG/SLS30I614/2025121212/2025121212.txt.gz\",\n",
    "    \"datalog/BRCG/SLS30I614/2025121212/2025121212.txt.gz\",\n",
    "    \"datalog/BRCG/SLS30I614/2025121212/2025121212.txt.gz\",\n",
    "    \"datalog/BRCG/SLS30I614/2025121212/2025121212.txt.gz\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ea95293",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"smartdbucket\"\n",
    "s3key_list_string = (\n",
    "    f\"['s3://{bucket_name}/\" + f\"', 's3://{bucket_name}/\".join(test_str) + \"']\"\n",
    ")\n",
    "s3key_list_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882be9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = list(range(0, 24))\n",
    "r = [f\"{i:02d}\" for i in r]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6491533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.select(pl.col(\"speedsource\")).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eeb0ae",
   "metadata": {},
   "source": [
    "'s3://smartdbucket/datalog/BRCB/SLS30I172/2025120705/2025120705.txt.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6928a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_OBJECT_KEY = \"s3://smartdbucket/datalog/BRCB/SLS30I172/2025120705/2025120705.txt.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6261943",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=storage_options[\"aws_access_key_id\"],\n",
    "    aws_secret_access_key=storage_options[\"aws_secret_access_key\"],\n",
    "    region_name=storage_options[\"aws_region\"],\n",
    ")\n",
    "response = s3.list_objects_v2(\n",
    "    Bucket=\"smartdbucket\", Prefix=\"datalogparquet/datalog/\", MaxKeys=10\n",
    ")\n",
    "\n",
    "print(f\"KeyCount: {response.get('KeyCount', 0)}\")\n",
    "print(f\"Contents: {response.get('Contents', [])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ff2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=storage_options[\"aws_access_key_id\"],\n",
    "    aws_secret_access_key=storage_options[\"aws_secret_access_key\"],\n",
    "    region_name=storage_options[\"aws_region\"],\n",
    ")\n",
    "try:\n",
    "    # Download the file\n",
    "    s3.download_file(\"smartdbucket\", S3_OBJECT_KEY, \"data\")\n",
    "    print(f\"Successfully downloaded {S3_OBJECT_KEY} to data\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c9956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.group_by(pl.col(pl.col('speedsource'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaa5ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull gzip data from s3\n",
    "s3 = s3fs.S3FileSystem(\n",
    "    key=storage_options[\"aws_access_key_id\"],\n",
    "    secret=storage_options[\"aws_secret_access_key\"],\n",
    ")\n",
    "\n",
    "\n",
    "filepath = f\"s3://{storage_options['aws_bucket']}/datalog/{distrik}/{deviceid}/{hivehour}/{hivehour}\"\n",
    "bucketpath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c7575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketpath = f\"s3://{storage_options['aws_bucket']}/datalog/{distrik}/{deviceid}/{hivehour}/{hivehour}.txt.gz\"\n",
    "df = conn.sql(f\"\"\"\n",
    "SELECT CAST(to_timestamp(heartbeat) as DATE)+ INTERVAL 8 HOUR as datetime_wita,gpsspeed,gpsnumsat,vehiclespeed,speedsource,\n",
    "FROM read_json_auto('{bucketpath}')\n",
    "WHERE gpsspeed > 0 AND VehicleSpeed > 0 AND speedsource = 'CANBus\n",
    "\n",
    "           \"\"\").pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57714e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(\"speedsource\") == \"CANBus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2683238",
   "metadata": {},
   "outputs": [],
   "source": [
    "px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1db097c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
